# æµ‹è¯•æ‰§è¡Œå™¨
import pytest
import sys
import os
import json
import subprocess
from pathlib import Path
from datetime import datetime
from utils.logger import Logger
from utils.yaml_reader import YamlReader

class TestRunner:
    """æµ‹è¯•æ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.logger = Logger().get_logger()
        self.yaml_reader = YamlReader()
        self.project_root = Path(__file__).parent.parent
        self._stop_requested = False
        
    def run_tests(self, test_config, progress_callback=None, log_callback=None, result_callback=None):
        """è¿è¡Œæµ‹è¯•"""
        self._stop_requested = False
        start_time = datetime.now()
        
        try:
            # æ›´æ–°é…ç½®æ–‡ä»¶
            self._update_test_config(test_config)
            
            # æ„å»ºpytestå‚æ•°
            pytest_args = self._build_pytest_args(test_config)
            
            # æ‰§è¡Œæµ‹è¯•
            results = self._execute_tests(
                pytest_args, 
                test_config,
                progress_callback,
                log_callback,
                result_callback
            )
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            # æ•´ç†ç»“æœ
            final_results = {
                'success': results.get('success', False),
                'message': results.get('message', 'æµ‹è¯•å®Œæˆ'),
                'statistics': results.get('statistics', {}),
                'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                'end_time': end_time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_duration': str(duration).split('.')[0],
                'test_details': results.get('test_details', []),
                'summary': results.get('summary', '')
            }
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}',
                'statistics': {},
                'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                'end_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_duration': '0:00:00',
                'test_details': [],
                'summary': f'æ‰§è¡Œå¤±è´¥: {e}'
            }
    
    def _update_test_config(self, test_config):
        """æ›´æ–°æµ‹è¯•é…ç½®æ–‡ä»¶"""
        try:
            config_data = {
                'router': test_config['router'],
                'browser': {
                    'headless': test_config['browser']['headless'],
                    'browser_type': 'chromium',
                    'viewport': {'width': 1920, 'height': 1080},
                    'slow_mo': 100
                },
                'test_settings': {
                    'screenshot_on_failure': test_config['browser']['screenshot_on_failure'],
                    'video_on_failure': test_config['browser']['video_on_failure'],
                    'parallel_workers': 1,
                    'retry_failed': 1
                },
                'report': {
                    'title': 'è·¯ç”±å™¨è‡ªåŠ¨åŒ–æµ‹è¯•æŠ¥å‘Š',
                    'language': 'zh-CN',
                    'include_screenshots': True,
                    'include_logs': True
                }
            }
            
            self.yaml_reader.write_yaml("config/test_config.yaml", config_data)
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°é…ç½®å¤±è´¥: {e}")
    
    def _build_pytest_args(self, test_config):
        """æ„å»ºpytestå‚æ•°"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"reports/outputs/test_report_{timestamp}.html"
        
        pytest_args = [
            "-v",  # è¯¦ç»†è¾“å‡º
            "--tb=short",  # ç®€çŸ­é”™è¯¯ä¿¡æ¯
            f"--html={report_file}",  # HTMLæŠ¥å‘Š
            "--self-contained-html",  # è‡ªåŒ…å«HTML
            "--capture=no",  # ä¸æ•è·è¾“å‡º
        ]
        
        # æ ¹æ®æµ‹è¯•åŠŸèƒ½é€‰æ‹©æµ‹è¯•æ–‡ä»¶
        test_function = test_config.get('test_function', 'å…¨éƒ¨åŠŸèƒ½')
        
        if test_function == 'ç™»å½•æµ‹è¯•':
            pytest_args.append("tests/test_login.py")
        elif test_function == 'VLANè®¾ç½®':
            pytest_args.append("tests/test_vlan.py")
        elif test_function == 'ç«¯å£æ˜ å°„':
            pytest_args.append("tests/test_port_mapping.py")
        elif test_function == 'ACLè§„åˆ™':
            pytest_args.append("tests/test_acl.py")
        else:
            pytest_args.append("tests/")
        
        return pytest_args
    
    def _execute_tests(self, pytest_args, test_config, progress_callback, log_callback, result_callback):
        """æ‰§è¡Œæµ‹è¯•"""
        cycles = test_config.get('cycles', 1)
        all_results = []
        total_stats = {'total': 0, 'passed': 0, 'failed': 0, 'skipped': 0, 'error': 0}
        
        for cycle in range(cycles):
            if self._stop_requested:
                break
                
            if log_callback:
                log_callback(f"ğŸ”„ å¼€å§‹ç¬¬ {cycle + 1}/{cycles} è½®æµ‹è¯•")
            
            if progress_callback:
                progress = int((cycle / cycles) * 80)  # 80% ç”¨äºæµ‹è¯•æ‰§è¡Œ
                progress_callback(f"æ‰§è¡Œè¿›åº¦: {progress}%")
            
            # æ‰§è¡Œå•è½®æµ‹è¯•
            cycle_result = self._run_single_cycle(pytest_args, cycle + 1, log_callback, result_callback)
            all_results.append(cycle_result)
            
            # ç´¯è®¡ç»Ÿè®¡
            cycle_stats = cycle_result.get('statistics', {})
            for key in total_stats:
                total_stats[key] += cycle_stats.get(key, 0)
        
        # è®¡ç®—æˆåŠŸç‡
        if total_stats['total'] > 0:
            success_rate = (total_stats['passed'] / total_stats['total']) * 100
        else:
            success_rate = 0
        
        total_stats['success_rate'] = success_rate
        
        # åˆ¤æ–­æ•´ä½“æˆåŠŸçŠ¶æ€
        overall_success = total_stats['failed'] == 0 and total_stats['error'] == 0 and total_stats['total'] > 0
        
        if progress_callback:
            progress_callback("æ‰§è¡Œè¿›åº¦: 100%")
        
        return {
            'success': overall_success,
            'message': f'å®Œæˆ {cycles} è½®æµ‹è¯•ï¼ŒæˆåŠŸç‡ {success_rate:.1f}%',
            'statistics': total_stats,
            'test_details': all_results,
            'summary': self._generate_summary(all_results, total_stats)
        }
    
    def _run_single_cycle(self, pytest_args, cycle_num, log_callback, result_callback):
        """è¿è¡Œå•è½®æµ‹è¯•"""
        try:
            if log_callback:
                log_callback(f"ğŸ“‹ æ‰§è¡Œå‘½ä»¤: pytest {' '.join(pytest_args)}")
            
            # ä½¿ç”¨subprocessè¿è¡Œpytestï¼Œè¿™æ ·å¯ä»¥æ›´å¥½åœ°æ§åˆ¶å’Œç›‘æ§
            result = subprocess.run(
                [sys.executable, "-m", "pytest"] + pytest_args,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            # è§£æpytestè¾“å‡º
            stats = self._parse_pytest_output(result.stdout, result.stderr)
            
            # è®°å½•ç»“æœ
            if result_callback:
                result_callback({
                    'test_case': f'ç¬¬{cycle_num}è½®æµ‹è¯•',
                    'status': 'PASSED' if result.returncode == 0 else 'FAILED',
                    'start_time': datetime.now().strftime('%H:%M:%S'),
                    'end_time': datetime.now().strftime('%H:%M:%S'),
                    'duration': 'ä¼°ç®—',
                    'message': f'é€€å‡ºç : {result.returncode}'
                })
            
            if log_callback:
                if result.returncode == 0:
                    log_callback(f"âœ… ç¬¬ {cycle_num} è½®æµ‹è¯•æˆåŠŸ")
                else:
                    log_callback(f"âŒ ç¬¬ {cycle_num} è½®æµ‹è¯•å¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                    
                # è¾“å‡ºéƒ¨åˆ†pytestæ—¥å¿—
                if result.stdout:
                    lines = result.stdout.split('\n')
                    for line in lines[-10:]:  # æ˜¾ç¤ºæœ€å10è¡Œ
                        if line.strip():
                            log_callback(f"ğŸ“‹ {line}")
            
            return {
                'cycle': cycle_num,
                'returncode': result.returncode,
                'statistics': stats,
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
        except subprocess.TimeoutExpired:
            if log_callback:
                log_callback(f"â° ç¬¬ {cycle_num} è½®æµ‹è¯•è¶…æ—¶")
            return {
                'cycle': cycle_num,
                'returncode': -1,
                'statistics': {'total': 0, 'passed': 0, 'failed': 1, 'skipped': 0, 'error': 0},
                'stdout': '',
                'stderr': 'æµ‹è¯•è¶…æ—¶'
            }
        except Exception as e:
            if log_callback:
                log_callback(f"âŒ ç¬¬ {cycle_num} è½®æµ‹è¯•å‡ºé”™: {e}")
            return {
                'cycle': cycle_num,
                'returncode': -1,
                'statistics': {'total': 0, 'passed': 0, 'failed': 0, 'skipped': 0, 'error': 1},
                'stdout': '',
                'stderr': str(e)
            }
    
    def _parse_pytest_output(self, stdout, stderr):
        """è§£æpytestè¾“å‡ºè·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {'total': 0, 'passed': 0, 'failed': 0, 'skipped': 0, 'error': 0}
        
        try:
            # æŸ¥æ‰¾pytestçš„ç»Ÿè®¡è¡Œ
            lines = stdout.split('\n') + stderr.split('\n')
            
            for line in lines:
                line = line.strip()
                
                # æŸ¥æ‰¾ç±»ä¼¼ "5 passed, 2 failed, 1 skipped" çš„è¡Œ
                if 'passed' in line or 'failed' in line or 'error' in line:
                    if '=' in line and ('passed' in line or 'failed' in line):
                        # è§£æç»Ÿè®¡ä¿¡æ¯
                        parts = line.split()
                        for i, part in enumerate(parts):
                            if part.isdigit() and i + 1 < len(parts):
                                count = int(part)
                                next_part = parts[i + 1].lower()
                                
                                if 'passed' in next_part:
                                    stats['passed'] = count
                                elif 'failed' in next_part:
                                    stats['failed'] = count
                                elif 'skipped' in next_part:
                                    stats['skipped'] = count
                                elif 'error' in next_part:
                                    stats['error'] = count
            
            # è®¡ç®—æ€»æ•°
            stats['total'] = stats['passed'] + stats['failed'] + stats['skipped'] + stats['error']
            
        except Exception as e:
            self.logger.error(f"è§£æpytestè¾“å‡ºå¤±è´¥: {e}")
        
        return stats
    
    def _generate_summary(self, all_results, total_stats):
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        summary_lines = []
        
        summary_lines.append(f"æ€»å…±æ‰§è¡Œäº† {len(all_results)} è½®æµ‹è¯•")
        summary_lines.append(f"æµ‹è¯•ç”¨ä¾‹æ€»æ•°: {total_stats['total']}")
        summary_lines.append(f"æˆåŠŸ: {total_stats['passed']}")
        summary_lines.append(f"å¤±è´¥: {total_stats['failed']}")
        summary_lines.append(f"è·³è¿‡: {total_stats['skipped']}")
        summary_lines.append(f"é”™è¯¯: {total_stats['error']}")
        summary_lines.append(f"æˆåŠŸç‡: {total_stats.get('success_rate', 0):.1f}%")
        
        # æ·»åŠ æ¯è½®ç»“æœ
        for i, result in enumerate(all_results, 1):
            returncode = result.get('returncode', -1)
            status = "æˆåŠŸ" if returncode == 0 else "å¤±è´¥"
            summary_lines.append(f"ç¬¬{i}è½®: {status}")
        
        return '\n'.join(summary_lines)
    
    def stop_tests(self):
        """åœæ­¢æµ‹è¯•"""
        self._stop_requested = True
        self.logger.info("æ”¶åˆ°åœæ­¢æµ‹è¯•è¯·æ±‚")